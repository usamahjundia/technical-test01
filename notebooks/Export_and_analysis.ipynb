{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o5awClqPXDtk"
      },
      "outputs": [],
      "source": [
        "!cp -r \"/content/drive/MyDrive/Professional Stuff/Technical Test/Verihubs\" ./model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K1nx_LPXgsx"
      },
      "outputs": [],
      "source": [
        "!curl -L -o ./face-mask-detection.zip https://www.kaggle.com/api/v1/datasets/download/andrewmvd/face-mask-detection\n",
        "!unzip -qq ./face-mask-detection.zip -d ./facemask_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j0z0h00AYm6Q",
        "outputId": "37e6eee4-640b-40eb-fd30-9d00358cb1fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rfdetr\n",
            "  Downloading rfdetr-1.4.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (from rfdetr) (2.0.11)\n",
            "Collecting torch<=2.8.0,>=1.13.0 (from rfdetr)\n",
            "  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: torchvision>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from rfdetr) (0.24.0+cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from rfdetr) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from rfdetr) (4.67.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rfdetr) (2.0.2)\n",
            "Collecting transformers<5.0.0,>4.0.0 (from rfdetr)\n",
            "  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from rfdetr) (0.18.1)\n",
            "Collecting polygraphy (from rfdetr)\n",
            "  Downloading polygraphy-0.49.26-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting rf100vl (from rfdetr)\n",
            "  Downloading rf100vl-1.1.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from rfdetr) (2.12.3)\n",
            "Collecting supervision (from rfdetr)\n",
            "  Downloading supervision-0.27.0.post1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from rfdetr) (3.10.0)\n",
            "Collecting roboflow (from rfdetr)\n",
            "  Downloading roboflow-1.2.13-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting pillow-avif-plugin<1.5.3 (from rfdetr)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting onnx (from rfdetr[onnxexport])\n",
            "  Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting onnxsim (from rfdetr[onnxexport])\n",
            "  Downloading onnxsim-0.4.36.tar.gz (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnx_graphsurgeon (from rfdetr[onnxexport])\n",
            "  Downloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting onnxruntime (from rfdetr[onnxexport])\n",
            "  Downloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=1.13.0->rfdetr) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=1.13.0->rfdetr) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=1.13.0->rfdetr) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=1.13.0->rfdetr) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=1.13.0->rfdetr) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=1.13.0->rfdetr) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<=2.8.0,>=1.13.0->rfdetr) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch<=2.8.0,>=1.13.0->rfdetr)\n",
            "  Downloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision>=0.14.0 (from rfdetr)\n",
            "  Downloading torchvision-0.25.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "  Downloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.14.0->rfdetr) (11.3.0)\n",
            "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers<5.0.0,>4.0.0->rfdetr)\n",
            "  Downloading huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>4.0.0->rfdetr) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>4.0.0->rfdetr) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>4.0.0->rfdetr) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>4.0.0->rfdetr) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>4.0.0->rfdetr) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>4.0.0->rfdetr) (0.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->rfdetr) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->rfdetr) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->rfdetr) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->rfdetr) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->rfdetr) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->rfdetr) (2.9.0.post0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx->rfdetr[onnxexport]) (5.29.5)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx->rfdetr[onnxexport]) (0.5.4)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime->rfdetr[onnxexport]) (25.12.19)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from onnxsim->rfdetr[onnxexport]) (13.9.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft->rfdetr) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft->rfdetr) (1.12.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->rfdetr) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->rfdetr) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->rfdetr) (0.4.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow->rfdetr) (2026.1.4)\n",
            "Collecting idna==3.7 (from roboflow->rfdetr)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow->rfdetr)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow->rfdetr) (1.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow->rfdetr) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow->rfdetr) (2.5.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow->rfdetr) (1.0.0)\n",
            "Collecting filetype (from roboflow->rfdetr)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pi-heif<2 (from roboflow->rfdetr)\n",
            "  Downloading pi_heif-1.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision->rfdetr) (0.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.12/dist-packages (from supervision->rfdetr) (4.13.0.90)\n",
            "Collecting pyDeprecate>=0.4.0 (from supervision->rfdetr)\n",
            "  Downloading pydeprecate-0.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>4.0.0->rfdetr) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>4.0.0->rfdetr) (3.4.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<=2.8.0,>=1.13.0->rfdetr) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<=2.8.0,>=1.13.0->rfdetr) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->onnxsim->rfdetr[onnxexport]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->onnxsim->rfdetr[onnxexport]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim->rfdetr[onnxexport]) (0.1.2)\n",
            "Downloading rfdetr-1.4.1-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.1/156.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading polygraphy-0.49.26-py2.py3-none-any.whl (372 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.8/372.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rf100vl-1.1.0-py3-none-any.whl (16 kB)\n",
            "Downloading roboflow-1.2.13-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading supervision-0.27.0.post1-py3-none-any.whl (217 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.4/217.4 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeprecate-0.4.0-py3-none-any.whl (21 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: onnxsim\n",
            "  Building wheel for onnxsim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for onnxsim: filename=onnxsim-0.4.36-cp312-cp312-linux_x86_64.whl size=2200379 sha256=53493633fdcee869a135aafc33d84bd1fc793ca145edbf7e7c003051c5fcf30e\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/5d/cc/db1350d9fabfe7f8442b5d97aff2ff543fc253277f71a6508f\n",
            "Successfully built onnxsim\n",
            "Installing collected packages: pillow-avif-plugin, nvidia-cusparselt-cu12, filetype, triton, pyDeprecate, polygraphy, pi-heif, opencv-python-headless, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, idna, onnxruntime, onnx, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, supervision, onnxsim, onnx_graphsurgeon, nvidia-cusolver-cu12, huggingface-hub, torch, roboflow, transformers, torchvision, rf100vl, rfdetr\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.13.0.90\n",
            "    Uninstalling opencv-python-headless-4.13.0.90:\n",
            "      Successfully uninstalled opencv-python-headless-4.13.0.90\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.29.2\n",
            "    Uninstalling nvidia-nccl-cu12-2.29.2:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.29.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface_hub 1.3.7\n",
            "    Uninstalling huggingface_hub-1.3.7:\n",
            "      Successfully uninstalled huggingface_hub-1.3.7\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cpu\n",
            "    Uninstalling torch-2.9.0+cpu:\n",
            "      Successfully uninstalled torch-2.9.0+cpu\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 5.0.0\n",
            "    Uninstalling transformers-5.0.0:\n",
            "      Successfully uninstalled transformers-5.0.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.24.0+cpu\n",
            "    Uninstalling torchvision-0.24.0+cpu:\n",
            "      Successfully uninstalled torchvision-0.24.0+cpu\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 huggingface-hub-0.36.2 idna-3.7 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 onnx-1.20.1 onnx_graphsurgeon-0.5.8 onnxruntime-1.24.1 onnxsim-0.4.36 opencv-python-headless-4.10.0.84 pi-heif-1.2.0 pillow-avif-plugin-1.5.2 polygraphy-0.49.26 pyDeprecate-0.4.0 rf100vl-1.1.0 rfdetr-1.4.1 roboflow-1.2.13 supervision-0.27.0.post1 torch-2.8.0 torchvision-0.23.0 transformers-4.57.6 triton-3.4.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "054a6c66c84d4f29b84055bc23a1b0ee",
              "pip_warning": {
                "packages": [
                  "idna"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# !pip install --quiet rfdetr rfdetr[onnxexport]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6SNlumTY8Ub",
        "outputId": "b7f0fb9d-3436-4862-8a18-ced770912d11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrain weights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:rfdetr.main:Reinitializing detection head with 4 classes\n"
          ]
        }
      ],
      "source": [
        "from rfdetr import RFDETRBase\n",
        "\n",
        "model = RFDETRBase(pretrain_weights=\"./model/checkpoint_best_total.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvwgGumyZOgc"
      },
      "source": [
        "## Conversion\n",
        "\n",
        "To optimize the model, i choose to export the model to onnx and will run it later using onnxruntime because in my experience onnxruntime supports multiple \"backends\". We can run it with GPU and CPU, even on ARM CPU. Even optimized backends for certain hardware, for example intel's openVINO is also supported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "_a9gvu6rcq3V",
        "outputId": "b7ce7d07-9d2b-4e62-9f73-bc259c2cdd23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnx==1.19\n",
            "  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx==1.19) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx==1.19) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx==1.19) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx==1.19) (0.5.4)\n",
            "Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "  Attempting uninstall: onnx\n",
            "    Found existing installation: onnx 1.20.1\n",
            "    Uninstalling onnx-1.20.1:\n",
            "      Successfully uninstalled onnx-1.20.1\n",
            "Successfully installed onnx-1.19.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "26c3c754dacb463f92b6f6786106da40",
              "pip_warning": {
                "packages": [
                  "onnx"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# !pip install -U onnx==1.19 rfdetr[onnxexport]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8OzxnIlZJUr",
        "outputId": "61ebea31-bb78-4307-e922-b5c717cfecb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exporting model to ONNX format\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch inference output shapes - Boxes: torch.Size([1, 3900, 4]), Labels: torch.Size([1, 3900, 4])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
            "TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
            "TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Successfully exported ONNX model: output/inference_model.onnx\n",
            "Successfully exported ONNX model to: output/inference_model.onnx\n",
            "start simplify ONNX model: output/inference_model.onnx\n",
            "[W] colored module is not installed, will not use colors when logging. To enable colors, please install the colored module: python3 -m pip install colored\n",
            "[I] load onnx file: output/inference_model.onnx\n",
            "[W] 'colored' module is not installed, will not use colors when logging. To enable colors, please install the 'colored' module: python3 -m pip install colored\n",
            "[I] Folding Constants | Pass 1\n",
            "[I]     Total Nodes | Original:  2008, After Folding:  1225 |   783 Nodes Folded\n",
            "[I] Folding Constants | Pass 2\n",
            "[I]     Total Nodes | Original:  1225, After Folding:  1026 |   199 Nodes Folded\n",
            "[I] Folding Constants | Pass 3\n",
            "[I]     Total Nodes | Original:  1026, After Folding:   945 |    81 Nodes Folded\n",
            "[I] Folding Constants | Pass 4\n",
            "[I]     Total Nodes | Original:   945, After Folding:   916 |    29 Nodes Folded\n",
            "[I] Folding Constants | Pass 5\n",
            "[I]     Total Nodes | Original:   916, After Folding:   883 |    33 Nodes Folded\n",
            "[I] Folding Constants | Pass 6\n",
            "[I]     Total Nodes | Original:   883, After Folding:   851 |    32 Nodes Folded\n",
            "[I] Folding Constants | Pass 7\n",
            "[I]     Total Nodes | Original:   851, After Folding:   837 |    14 Nodes Folded\n",
            "[I] Folding Constants | Pass 8\n",
            "[I]     Total Nodes | Original:   837, After Folding:   837 |     0 Nodes Folded\n",
            "[W] colored module is not installed, will not use colors when logging. To enable colors, please install the colored module: python3 -m pip install colored\n",
            "[I] save onnx file: output/inference_model.sim.onnx\n",
            "Checking 0/3...\n",
            "Checking 1/3...\n",
            "Checking 2/3...\n",
            "Successfully simplified ONNX model: output/inference_model.sim.onnx\n",
            "Successfully simplified ONNX model to: output/inference_model.sim.onnx\n",
            "ONNX export completed successfully\n"
          ]
        }
      ],
      "source": [
        "model.export(simplify=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMoXlNS8eVBB",
        "outputId": "3b173ce9-6f1d-499d-d1f1-4557bebd2f1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: output/inference_model.onnx (deflated 14%)\n",
            "  adding: output/inference_model.sim.onnx (deflated 11%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r onnx_export.zip output/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sfBrX9EielXw"
      },
      "outputs": [],
      "source": [
        "!cp onnx_export.zip /content/drive/MyDrive/Professional\\ Stuff/Technical\\ Test/Verihubs/onnx_export.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwiS7ooLeyRu"
      },
      "source": [
        "After exporting, let's see how our training goes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6su3BiOdaaeB",
        "outputId": "eb6dab28-db62-4c79-d87c-066bcf92258f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evals for class with_mask:\n",
            " - map@50:95: 0.6387706161950641\n",
            " - map@50: 0.9496308582993108\n",
            " - precision: 0.9281842818428184\n",
            " - recall: 0.9332425068119891\n",
            " - f1_score: 0.9307065217391305\n",
            "Evals for class without_mask:\n",
            " - map@50:95: 0.5061049133288853\n",
            " - map@50: 0.8529987209222274\n",
            " - precision: 0.9060773480662984\n",
            " - recall: 0.7488584474885844\n",
            " - f1_score: 0.82\n",
            "Evals for class mask_weared_incorrect:\n",
            " - map@50:95: 0.3910092995812707\n",
            " - map@50: 0.5680709653479304\n",
            " - precision: 0.7619047619047619\n",
            " - recall: 0.48484848484848486\n",
            " - f1_score: 0.5925925925925926\n",
            "Evals for class all:\n",
            " - map@50:95: 0.51196160970174\n",
            " - map@50: 0.7902335148564896\n",
            " - precision: 0.8653887972712928\n",
            " - recall: 0.7223164797163527\n",
            " - f1_score: 0.7810997047772409\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open(\"./model/results.json\") as f:\n",
        "    training_evals = json.load(f)\n",
        "\n",
        "for classmap in training_evals[\"class_map\"][\"valid\"]:\n",
        "    for key, value in classmap.items():\n",
        "        if key == \"class\":\n",
        "            print(f\"Evals for class {value}:\")\n",
        "        else:\n",
        "            print(f\" - {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB0A16a5eMV8"
      },
      "source": [
        "As expected, the minority class suffers the most. Let's also try to see if it's also the case in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQzXvge8eIGg",
        "outputId": "2d930d0b-8429-4a3a-84f7-722673e52eee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evals for class with_mask:\n",
            " - map@50:95: 0.6411089733597557\n",
            " - map@50: 0.9414547708314025\n",
            " - precision: 0.9156769596199525\n",
            " - recall: 0.8954703832752613\n",
            " - f1_score: 0.905460951262478\n",
            "Evals for class without_mask:\n",
            " - map@50:95: 0.5197312392912448\n",
            " - map@50: 0.8597412628612452\n",
            " - precision: 0.8067226890756303\n",
            " - recall: 0.8067226890756303\n",
            " - f1_score: 0.8067226890756303\n",
            "Evals for class mask_weared_incorrect:\n",
            " - map@50:95: 0.3655878718428366\n",
            " - map@50: 0.5475340345824206\n",
            " - precision: 0.7857142857142857\n",
            " - recall: 0.4782608695652174\n",
            " - f1_score: 0.5945945945945946\n",
            "Evals for class all:\n",
            " - map@50:95: 0.5088093614979458\n",
            " - map@50: 0.782910022758356\n",
            " - precision: 0.8360379781366228\n",
            " - recall: 0.7268179806387031\n",
            " - f1_score: 0.768926078310901\n"
          ]
        }
      ],
      "source": [
        "for classmap in training_evals[\"class_map\"][\"test\"]:\n",
        "    for key, value in classmap.items():\n",
        "        if key == \"class\":\n",
        "            print(f\"Evals for class {value}:\")\n",
        "        else:\n",
        "            print(f\" - {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhmnyJUofbkE"
      },
      "source": [
        "Looking at the scores, it seems like the performence is close between eval and test, meaning the problem is not overfitting (variance) but is simply that we have too little data for the other classes. For the next runs, it is probably wiser to use per-class loss weighting.\n",
        "\n",
        "### First analysis: box accuracy / precision\n",
        "\n",
        "Overall, we can see that the map@50 is pretty far from the map@50:95. Meaning the model can somewhat reliably locate the faces, but it still struggles to put a tight fit around the object, either the box is not perfectly centered on the object or the box is too small / too big. TL;DR, its great at finding the general location, but pretty horrible at making sure the box is a tight fit, which may or may not be that big of a deal, depending on the use case. Again, the requirement doesnt really say anything so i can just analyze generally.\n",
        "\n",
        "We can also see how much worse it is for the minority class (wrongmask). It follows a trend where the less images the class have, the lower it gets. We still see a healthy distance between the validation and test set performance though, so I'd say we're not suffering from overfitting, just need more data and variety for the minority class.\n",
        "\n",
        "The cause can vary. It could be the images are too low quality, it could be we need better augmentations, it could be we havent trained long enough, it could also be that we need to rebalance the bbox loss vs classification loss during training. We will see later when we do visual inspection.\n",
        "\n",
        "### Second analysis: precision-recall disparity\n",
        "\n",
        "For the withmask and nomask classes, the precision and recall isnt too far apart. Meaning the false positives and false negatives are pretty balanced. \n",
        "\n",
        "Meanwhile for the wrongmask class, we can see the huge gap between the precision and recall. The recall is much lower, meaning the model is struggling with false negatives. Put simply, the model **FAILS** finding wrongmask faces. I can be like a broken radio and say we need more data, but on future runs, i think it is wise to apply a class weighting on our loss function so the model can pay more attention to the minority class. Oversampling the minority class might be another solution but it's probably redundant if we're using class weighting anyways. \n",
        "\n",
        "Interestingly enough, the nomask class has quite a disparity between validation and test\n",
        "\n",
        "validation has precision in the 90s and recall 74, while recall is pretty balanced having both in the 80 ish range. I think despite our earlier effort, there is still quite a distribution difference that will need a better splitting method when we're creating our validation set. My hypothesis is that it's the images with a lot of nomask faces that tanks the validation recall.\n",
        "\n",
        "\n",
        "\n",
        "Overall, most things are as expected, not many surprises here."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
